{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning Tutorials\n",
    "\n",
    "Run the cell below if you need to install the required libraries. In Google Colab they come pre-installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering\n",
    "\n",
    "k-means partitions observations into `k` groups by iteratively updating cluster assignments and centroids. Starting with randomly chosen centroids, each iteration performs two steps:\n",
    "1. **Assign step:** assign each sample to the nearest centroid using Euclidean distance.\n",
    "2. **Update step:** recompute each centroid as the mean of all samples assigned to it.\n",
    "\n",
    "The goal is to minimize the within-cluster sum of squared distances\\n",
    "$$\\nJ = \\sum_{i=1}^n \\|x_i - \\mu_{c_i}\\|^2,\\n$$\n",
    "where $x_i$ is a sample and $\\mu_{c_i}$ is the centroid of its cluster. Iterations stop once assignments stabilize or a maximum iteration count is reached."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def kmeans_scratch(X, k, max_iter=100, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    centroids = X[rng.choice(len(X), size=k, replace=False)]\n",
    "    for _ in range(max_iter):\n",
    "        dists = np.linalg.norm(X[:, None] - centroids[None], axis=2)\n",
    "        labels = dists.argmin(axis=1)\n",
    "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n",
    "        if np.allclose(new_centroids, centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return labels, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, _ = load_iris(return_X_y=True)\n",
    "scratch_labels, scratch_centers = kmeans_scratch(X, k=3)\n",
    "print('Cluster counts (scratch):', np.bincount(scratch_labels))\n",
    "print('Centroids (scratch):', scratch_centers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn k-means\n",
    "\n",
    "`KMeans` provides a highly optimized implementation of the same algorithm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "sk_labels = kmeans.fit_predict(X)\n",
    "print('Cluster counts (scikit-learn):', np.bincount(sk_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=sk_labels, cmap='viridis', s=30)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c='red', marker='x', s=100, linewidths=2, label='Centers')\n",
    "plt.title('k-means Clustering')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis\n",
    "\n",
    "PCA reduces dimensionality by projecting data onto directions that maximize variance. For a centered data matrix $X$, the covariance matrix $C = \\frac{1}{n-1} X^T X$ is eigendecomposed. The top eigenvectors form the projection matrix. The projected samples are $Z = X W$ and the eigenvalues determine the explained variance ratio."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pca_scratch(X, n_components=2):\n",
    "    X_c = X - X.mean(axis=0)\n",
    "    cov = np.cov(X_c, rowvar=False)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    components = eigvecs[:, :n_components]\n",
    "    explained = eigvals[:n_components] / eigvals.sum()\n",
    "    reduced = X_c @ components\n",
    "    return reduced, explained\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "scratch_reduced, scratch_ratio = pca_scratch(X, n_components=2)\n",
    "print('Explained variance ratio (scratch):', scratch_ratio)\n",
    "print('Reduced shape:', scratch_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn PCA\n",
    "\n",
    "`PCA` performs the eigen decomposition for us and exposes the variance ratio via `explained_variance_ratio_`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "sk_reduced = pca.fit_transform(X)\n",
    "print('Explained variance ratio (scikit-learn):', pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(sk_reduced[:,0], sk_reduced[:,1], c=y, cmap='tab10', s=15)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA of Digits')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the brief tour of unsupervised learning examples with and without scikit-learn. Feel free to experiment with other datasets or algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
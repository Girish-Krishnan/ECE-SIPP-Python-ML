{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Tutorials\n",
    "\n",
    "This notebook demonstrates basic reinforcement learning with Stable Baselines3 and Gymnasium environments.\n",
    "\n",
    "Run the cell below if you need to install the required libraries. In Google Colab they will be installed when you execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3 gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO, DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Train PPO on CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "video_env = gym.wrappers.RecordVideo(\n",
    "    gym.make('CartPole-v1', render_mode='rgb_array'),\n",
    "    video_folder='videos',\n",
    "    name_prefix='ppo_cartpole',\n",
    "    episode_trigger=lambda e: True,\n",
    ")\n",
    "obs, _ = video_env.reset()\n",
    "terminated, truncated = False, False\n",
    "while not (terminated or truncated):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, terminated, truncated, _ = video_env.step(action)\n",
    "video_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train DQN on MountainCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=50000)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "video_env = gym.wrappers.RecordVideo(\n",
    "    gym.make('MountainCar-v0', render_mode='rgb_array'),\n",
    "    video_folder='videos',\n",
    "    name_prefix='dqn_mountaincar',\n",
    "    episode_trigger=lambda e: True,\n",
    ")\n",
    "obs, _ = video_env.reset()\n",
    "terminated, truncated = False, False\n",
    "while not (terminated or truncated):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, terminated, truncated, _ = video_env.step(action)\n",
    "video_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Humanoid example (requires Mujoco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Humanoid-v4')\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "video_env = gym.wrappers.RecordVideo(\n",
    "    gym.make('Humanoid-v4', render_mode='rgb_array'),\n",
    "    video_folder='videos',\n",
    "    name_prefix='ppo_humanoid',\n",
    "    episode_trigger=lambda e: True,\n",
    ")\n",
    "obs, _ = video_env.reset()\n",
    "terminated, truncated = False, False\n",
    "while not (terminated or truncated):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, terminated, truncated, _ = video_env.step(action)\n",
    "video_env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
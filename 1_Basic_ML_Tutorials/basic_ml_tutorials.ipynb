{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Basic Machine Learning Tutorials\n", "\n", "This notebook walks through simple scikit-learn examples step by step.\n", "\n", "Run the cell below if you need to install the required libraries. In Google Colab they come pre-installed."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install scikit-learn matplotlib"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0. Linear regression on synthetic data\n", "\n", "Generate a noisy 1D dataset and fit a linear regression model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.datasets import make_regression\n", "from sklearn.linear_model import LinearRegression\n", "import matplotlib.pyplot as plt\n", "\n", "X, y, coef = make_regression(n_samples=100, n_features=1, noise=10.0, coef=True, random_state=42)\n", "model = LinearRegression()\n", "model.fit(X, y)\n", "print('True coefficient:', coef)\n", "print('Learned coefficient:', model.coef_[0])\n", "print('Intercept:', model.intercept_)\n", "\n", "x_grid = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n", "y_pred = model.predict(x_grid)\n", "plt.scatter(X, y, color='blue', label='Data')\n", "plt.plot(x_grid, y_pred, color='red', label='Fit')\n", "plt.xlabel('Feature')\n", "plt.ylabel('Target')\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Logistic regression on Iris\n", "\n", "Train a logistic regression classifier on the Iris dataset and report accuracy."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n", "import matplotlib.pyplot as plt\n", "\n", "X, y = load_iris(return_X_y=True)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n", "clf = LogisticRegression(max_iter=200)\n", "clf.fit(X_train, y_train)\n", "preds = clf.predict(X_test)\n", "print('Accuracy:', accuracy_score(y_test, preds))\n", "ConfusionMatrixDisplay.from_predictions(y_test, preds)\n", "plt.title('Logistic Regression Confusion Matrix')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. k-NN classification on digits\n", "\n", "Use a 3-nearest-neighbor classifier on the handwritten digits dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_digits\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n", "import matplotlib.pyplot as plt\n", "\n", "X, y = load_digits(return_X_y=True)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n", "knn = KNeighborsClassifier(n_neighbors=3)\n", "knn.fit(X_train, y_train)\n", "preds = knn.predict(X_test)\n", "print('Test accuracy:', accuracy_score(y_test, preds))\n", "ConfusionMatrixDisplay.from_predictions(y_test, preds)\n", "plt.title('k-NN Confusion Matrix')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Decision tree classifier\n", "\n", "Fit a shallow decision tree on the Iris dataset and show the classification report."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n", "import matplotlib.pyplot as plt\n", "\n", "X, y = load_iris(return_X_y=True)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n", "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n", "tree.fit(X_train, y_train)\n", "preds = tree.predict(X_test)\n", "print(classification_report(y_test, preds))\n", "ConfusionMatrixDisplay.from_predictions(y_test, preds)\n", "plt.title('Decision Tree Confusion Matrix')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. k-means clustering\n", "\n", "Cluster the Iris dataset into three groups using k-means."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "from sklearn.cluster import KMeans\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "X, y = load_iris(return_X_y=True)\n", "kmeans = KMeans(n_clusters=3, random_state=42)\n", "clusters = kmeans.fit_predict(X)\n", "print('Cluster counts:', np.bincount(clusters))\n", "print('Cluster centers:\n', kmeans.cluster_centers_)\n", "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', s=30)\n", "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=100, linewidths=2, label='Centers')\n", "plt.title('k-means Clustering')\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Principal component analysis\n", "\n", "Reduce the dimensionality of the digits dataset to two components using PCA."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_digits\n", "from sklearn.decomposition import PCA\n", "import matplotlib.pyplot as plt\n", "\n", "X, y = load_digits(return_X_y=True)\n", "pca = PCA(n_components=2)\n", "reduced = pca.fit_transform(X)\n", "print('Explained variance ratio:', pca.explained_variance_ratio_)\n", "print('Transformed shape:', reduced.shape)\n", "plt.scatter(reduced[:, 0], reduced[:, 1], c=y, cmap='tab10', s=15)\n", "plt.xlabel('PC1')\n", "plt.ylabel('PC2')\n", "plt.title('PCA of Digits')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This concludes the brief tour of basic machine learning examples using scikit-learn. Feel free to modify the code cells and explore further!"]}], "metadata": {"kernelspec": {"display_name": "cogs", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.5"}}, "nbformat": 4, "nbformat_minor": 4}
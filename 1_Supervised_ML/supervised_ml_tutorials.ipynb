{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c674e36c",
      "metadata": {},
      "source": [
        "# Supervised Learning: from scratch and with scikit-learn\n",
        "\n",
        "Examples showing the math behind basic algorithms and their scikit-learn counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276594dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install numpy scikit-learn matplotlib -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b9e5246",
      "metadata": {},
      "source": [
        "Scikit-learn is a powerful library for machine learning in Python, providing efficient tools for data mining and data analysis. It is built on NumPy, SciPy, and matplotlib.\n",
        "\n",
        "Documentation: [scikit-learn documentation](https://scikit-learn.org/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a3e91e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression, make_classification, load_digits, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Perceptron, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afcef169",
      "metadata": {},
      "source": [
        "## 0. Linear regression from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d426fe5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y, true_coef = make_regression(n_samples=100, n_features=1, noise=10.0, coef=True, random_state=42)\n",
        "X_b = np.c_[np.ones((len(X),1)), X]\n",
        "theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
        "print(\"True coef:\", true_coef)\n",
        "print(\"Closed-form coef:\", theta[1])\n",
        "print(\"Intercept:\", theta[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698983d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_grid = np.linspace(X.min(), X.max(), 100).reshape(-1,1)\n",
        "y_pred = theta[1]*x_grid + theta[0]\n",
        "plt.scatter(X, y, color=\"blue\", label=\"data\")\n",
        "plt.plot(x_grid, y_pred, color=\"red\", label=\"fit\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147fefed",
      "metadata": {},
      "source": [
        "### scikit-learn linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e88d6c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "print(\"sklearn coef:\", model.coef_[0])\n",
        "print(\"sklearn intercept:\", model.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f29f76",
      "metadata": {},
      "source": [
        "## 1. k-NN classification from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6b8c35",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "def knn_predict(X_train, y_train, X_test, k=3):\n",
        "    preds = []\n",
        "    for x in X_test:\n",
        "        dists = np.linalg.norm(X_train - x, axis=1)\n",
        "        idx = np.argsort(dists)[:k]\n",
        "        preds.append(np.bincount(y_train[idx]).argmax())\n",
        "    return np.array(preds)\n",
        "\n",
        "preds = knn_predict(X_train, y_train, X_test, k=3)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f60ba4a",
      "metadata": {},
      "source": [
        "### scikit-learn k-NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa882dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "sk_preds = knn.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, sk_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb9a12a",
      "metadata": {},
      "source": [
        "## 2. Perceptron with gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abbe288",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=200, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "y_train_signed = np.where(y_train==0, -1, 1)\n",
        "w = np.zeros(X_train.shape[1])\n",
        "b = 0.\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "for _ in range(100):\n",
        "    margins = y_train_signed * (X_train @ w + b)\n",
        "    mask = margins < 0\n",
        "    if not mask.any():\n",
        "        break\n",
        "    grad_w = -(y_train_signed[mask,None] * X_train[mask]).mean(axis=0)\n",
        "    grad_b = -(y_train_signed[mask]).mean()\n",
        "    w -= learning_rate * grad_w\n",
        "    b -= learning_rate * grad_b\n",
        "preds = (X_test @ w + b >= 0).astype(int)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e06fce",
      "metadata": {},
      "source": [
        "### scikit-learn Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829b14ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "skp = Perceptron(max_iter=1000, eta0=0.1, tol=1e-3)\n",
        "skp.fit(X_train, y_train)\n",
        "sk_preds = skp.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, sk_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d522c6",
      "metadata": {},
      "source": [
        "## 3. Logistic regression from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0134d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_iris(return_X_y=True)\n",
        "mask = y < 2\n",
        "X = X[mask, :2]\n",
        "y = y[mask]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "w = np.zeros(X_train.shape[1])\n",
        "b = 0.\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "for _ in range(200):\n",
        "    z = X_train @ w + b\n",
        "    preds = sigmoid(z)\n",
        "    grad_w = X_train.T @ (preds - y_train) / len(y_train)\n",
        "    grad_b = np.mean(preds - y_train)\n",
        "    w -= 0.1 * grad_w\n",
        "    b -= 0.1 * grad_b\n",
        "preds = (sigmoid(X_test @ w + b) >= 0.5).astype(int)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bb3178",
      "metadata": {},
      "source": [
        "### scikit-learn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddbbfdfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = LogisticRegression(max_iter=200)\n",
        "clf.fit(X_train, y_train)\n",
        "sk_preds = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, sk_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6735e099",
      "metadata": {},
      "source": [
        "This concludes the basic examples."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cogs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Tutorials\n",
    "\n",
    "This notebook walks through basic NLP tasks step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk scikit-learn transformers spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "from spacy.cli import download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Tokenize text with NLTK\n",
    "\n",
    "Tokenization splits text into individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "text = 'Natural language processing with Python is fun!'\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag-of-words representation\n",
    "\n",
    "Count how often each word appears in a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['I love coding in Python', 'Python can be used for NLP']\n",
    "vectorizer = CountVectorizer()\n",
    "bag = vectorizer.fit_transform(docs)\n",
    "print('Vocabulary:', vectorizer.vocabulary_)\n",
    "print('Bag-of-words matrix:\n', bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a text classifier\n",
    "\n",
    "Train a logistic regression model on two newsgroup categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['rec.sport.baseball', 'sci.space']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','footers','quotes'))\n",
    "test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers','footers','quotes'))\n",
    "clf = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000))\n",
    "clf.fit(train.data, train.target)\n",
    "preds = clf.predict(test.data)\n",
    "print(classification_report(test.target, preds, target_names=test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment analysis with transformers\n",
    "\n",
    "Use a pretrained model from Hugging Face to classify a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline('sentiment-analysis')\n",
    "result = sentiment('I love using transformers for NLP!')[0]\n",
    "print(f\"Label: {result['label']}, score: {result['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Named entity recognition with spaCy\n",
    "\n",
    "Recognize people, organizations and more in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Apple was founded by Steve Jobs in California.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Word embeddings and similarity\n",
    "\n",
    "Word vectors allow us to compare semantic similarity between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp_md = spacy.load('en_core_web_md')\n",
    "except OSError:\n",
    "    download('en_core_web_md')\n",
    "    nlp_md = spacy.load('en_core_web_md')\n",
    "tokens = nlp_md('dog cat banana')\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(f'Similarity({t1.text}, {t2.text}) = {t1.similarity(t2):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

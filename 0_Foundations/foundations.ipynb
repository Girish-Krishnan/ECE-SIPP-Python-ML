{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations: NumPy, pandas and Matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use **Jupyter notebooks**. Each cell can be run individually by clicking the play button or using `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. NumPy basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create arrays from Python lists\n",
    "a = np.array([1, 2, 3])\n",
    "print(\"1D array:\", a)\n",
    "\n",
    "# Create a 2D array of zeros\n",
    "b = np.zeros((2, 3))\n",
    "print(\"\\n2D zeros array:\\n\", b)\n",
    "\n",
    "# Create a 3x3 identity matrix\n",
    "c = np.eye(3)\n",
    "print(\"\\nIdentity matrix:\\n\", c)\n",
    "\n",
    "# More array creation tricks\n",
    "d = np.arange(12).reshape(3, 4)\n",
    "print(\"\\nReshaped array:\\n\", d)\n",
    "\n",
    "e = np.full((2, 2), 7)\n",
    "print(\"\\nConstant array:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Array math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"x + y =\", x + y)\n",
    "print(\"x * y =\", x * y)\n",
    "\n",
    "# Dot product\n",
    "print(\"x dot y =\", x @ y)\n",
    "\n",
    "# Vectorized functions\n",
    "print(\"sin(x) =\", np.sin(x))\n",
    "\n",
    "# Aggregations\n",
    "print(\"mean of y =\", y.mean())\n",
    "\n",
    "# Broadcasting with a scalar\n",
    "print(\"y squared =\", y ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(10)\n",
    "print(\"a =\", a)\n",
    "\n",
    "# Basic slicing\n",
    "print(\"a[2:5] =\", a[2:5])\n",
    "\n",
    "# Negative step slicing\n",
    "print(\"reverse =\", a[::-1])\n",
    "\n",
    "# Boolean masking\n",
    "mask = a % 2 == 0\n",
    "print(\"even elements =\", a[mask])\n",
    "\n",
    "# Fancy indexing\n",
    "idx = [1, 3, 5]\n",
    "print(\"selected indices =\", a[idx])\n",
    "\n",
    "# Adding a new axis\n",
    "col_vec = a[:, np.newaxis]\n",
    "print(\"\\ncolumn vector shape:\", col_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(3)\n",
    "print(\"x =\", x)\n",
    "\n",
    "# Add a scalar (broadcast)\n",
    "print(\"x + 5 =\", x + 5)\n",
    "\n",
    "# Add a 2D column vector to a row vector\n",
    "a = x.reshape(3, 1)\n",
    "b = np.array([10, 20, 30])\n",
    "print(\"\\na =\\n\", a)\n",
    "print(\"b =\", b)\n",
    "print(\"a + b =\\n\", a + b)\n",
    "\n",
    "# Multiply by a row vector\n",
    "m = np.ones((2, 3))\n",
    "print(\"\\nm =\\n\", m)\n",
    "print(\"m * x =\\n\", m * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random numbers & statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Random samples from a normal distribution\n",
    "samples = np.random.randn(1000)\n",
    "print(\"first five samples:\", samples[:5])\n",
    "\n",
    "# Compute basic statistics\n",
    "print(\"mean =\", samples.mean())\n",
    "print(\"std =\", samples.std())\n",
    "\n",
    "print(\"25th percentile =\", np.percentile(samples, 25))\n",
    "\n",
    "# Histogram (counts per bin)\n",
    "hist, bins = np.histogram(samples, bins=5)\n",
    "print(\"\\nhistogram:\")\n",
    "for b_left, b_right, count in zip(bins[:-1], bins[1:], hist):\n",
    "    print(f\"{b_left: .2f} to {b_right: .2f}: {count}\")\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.7)\n",
    "plt.title(\"Histogram of random samples\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Polynomial fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Create noisy quadratic data\n",
    "rng = np.random.default_rng(0)\n",
    "x = np.linspace(-3, 3, 20)\n",
    "y = 0.5 * x**2 - x + 2 + rng.normal(scale=1.0, size=x.shape)\n",
    "\n",
    "# Fit a second degree polynomial\n",
    "coeffs = np.polyfit(x, y, deg=2)\n",
    "print(\"coefficients:\", coeffs)\n",
    "\n",
    "# Evaluate the fitted polynomial\n",
    "p = np.poly1d(coeffs)\n",
    "y_fit = p(x)\n",
    "\n",
    "# Show first few fitted values\n",
    "print(\"\\nfirst 5 fitted values:\", y_fit[:5])\n",
    "\n",
    "# Plot the data and fitted curve\n",
    "plt.scatter(x, y, label=\"data\")\n",
    "plt.plot(x, y_fit, color=\"red\", label=\"fit\")\n",
    "plt.title(\"Polynomial fit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(9).reshape(3, 3)\n",
    "print(\"Original array:\\n\", arr)\n",
    "\n",
    "np.save('array.npy', arr)\n",
    "print('Array saved to array.npy')\n",
    "\n",
    "loaded = np.load('array.npy')\n",
    "print('Loaded array:\\n', loaded)\n",
    "\n",
    "# Save multiple arrays in a compressed npz\n",
    "np.savez_compressed('arrays.npz', first=arr, second=arr * 2)\n",
    "data = np.load('arrays.npz')\n",
    "print('\\nArrays in npz:', list(data.keys()))\n",
    "\n",
    "np.savetxt('array.txt', arr, fmt='%d')\n",
    "print('Also saved to array.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vectorization speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "n = 1000000\n",
    "data = np.arange(n)\n",
    "\n",
    "# Sum using Python loop\n",
    "start = time.time()\n",
    "total = 0\n",
    "for value in data:\n",
    "    total += value\n",
    "loop_time = time.time() - start\n",
    "\n",
    "# Sum using vectorized operation\n",
    "start = time.time()\n",
    "vector_total = np.sum(data)\n",
    "vector_time = time.time() - start\n",
    "\n",
    "print(\"loop sum =\", total, \"took\", loop_time, \"seconds\")\n",
    "print(\"vectorized sum =\", vector_total, \"took\", vector_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. pandas basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame from a Python dictionary\n",
    "data = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"age\": [25, 30, 35, 40],\n",
    "    \"score\": [85.5, 92.0, 88.0, 95.5],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\\n\", df, \"\\n\")\n",
    "\n",
    "# Basic selection and summary statistics\n",
    "print(\"Names column:\\n\", df[\"name\"])\n",
    "print(\"Average age:\", df[\"age\"].mean())\n",
    "print(\"Describe scores:\\n\", df[\"score\"].describe())\n",
    "\n",
    "# Simple visualization of the scores\n",
    "df.plot.bar(x=\"name\", y=\"score\", title=\"Participant scores\", legend=False)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"name\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "# Load the Iris dataset from scikit-learn and put it in a DataFrame\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df[\"target\"] = iris.target\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First five rows:\\n\", df.head(), \"\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics:\\n\", df.describe(), \"\\n\")\n",
    "\n",
    "# Scatter plot of two features\n",
    "df.plot.scatter(x=\"sepal length (cm)\", y=\"petal length (cm)\", c=\"target\", cmap=\"viridis\")\n",
    "plt.title(\"Iris feature scatter plot\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram of petal widths\n",
    "df[\"petal width (cm)\"].hist(bins=20)\n",
    "plt.title(\"Petal width distribution\")\n",
    "plt.xlabel(\"width (cm)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. CSV input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a simple DataFrame\n",
    "data = {\n",
    "    \"city\": [\"San Diego\", \"Los Angeles\", \"San Francisco\"],\n",
    "    \"population\": [1.4, 3.9, 0.88],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df, \"\\n\")\n",
    "\n",
    "# Write the DataFrame to CSV\n",
    "csv_path = \"cities.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data written to {csv_path}\")\n",
    "\n",
    "# Read the file back in\n",
    "loaded = pd.read_csv(csv_path)\n",
    "print(\"\\nLoaded from CSV:\\n\", loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. CIFAR-10 image exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "# Download CIFAR-10 training data\n",
    "transform = transforms.ToTensor()\n",
    "cifar = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "print(\"Number of images:\", len(cifar))\n",
    "\n",
    "loader = DataLoader(cifar, batch_size=4, shuffle=True)\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "# Plot a few sample images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for img, ax in zip(images, axes):\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"CIFAR-10 samples\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

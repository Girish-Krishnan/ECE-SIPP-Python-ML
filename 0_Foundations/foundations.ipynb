{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations: NumPy, pandas and Matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use **Jupyter notebooks**. Each cell can be run individually by clicking the play button or using `Shift+Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. NumPy basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n# Create arrays from Python lists\na = np.array([1, 2, 3])\nprint(\"1D array:\", a)\n\n# Create a 2D array of zeros\nb = np.zeros((2, 3))\nprint(\"\\n2D zeros array:\\n\", b)\n\n# Create a 3x3 identity matrix\nc = np.eye(3)\nprint(\"\\nIdentity matrix:\\n\", c)\n\n# More array creation tricks\nd = np.arange(12).reshape(3, 4)\nprint(\"\\nReshaped array:\\n\", d)\n\ne = np.full((2, 2), 7)\nprint(\"\\nConstant array:\\n\", e)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Array math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nx = np.array([1, 2, 3])\ny = np.array([4, 5, 6])\n\n# Element-wise operations\nprint(\"x + y =\", x + y)\nprint(\"x * y =\", x * y)\n\n# Dot product\nprint(\"x dot y =\", x @ y)\n\n# Vectorized functions\nprint(\"sin(x) =\", np.sin(x))\n\n# Aggregations\nprint(\"mean of y =\", y.mean())\n\n# Broadcasting with a scalar\nprint(\"y squared =\", y ** 2)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\na = np.arange(10)\nprint(\"a =\", a)\n\n# Basic slicing\nprint(\"a[2:5] =\", a[2:5])\n\n# Negative step slicing\nprint(\"reverse =\", a[::-1])\n\n# Boolean masking\nmask = a % 2 == 0\nprint(\"even elements =\", a[mask])\n\n# Fancy indexing\nidx = [1, 3, 5]\nprint(\"selected indices =\", a[idx])\n\n# Adding a new axis\ncol_vec = a[:, np.newaxis]\nprint(\"\\ncolumn vector shape:\", col_vec.shape)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nx = np.arange(3)\nprint(\"x =\", x)\n\n# Add a scalar (broadcast)\nprint(\"x + 5 =\", x + 5)\n\n# Add a 2D column vector to a row vector\na = x.reshape(3, 1)\nb = np.array([10, 20, 30])\nprint(\"\\na =\\n\", a)\nprint(\"b =\", b)\nprint(\"a + b =\\n\", a + b)\n\n# Multiply by a row vector\nm = np.ones((2, 3))\nprint(\"\\nm =\\n\", m)\nprint(\"m * x =\\n\", m * x)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random numbers & statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport matplotlib.pyplot as plt\n# Random samples from a normal distribution\nsamples = np.random.randn(1000)\nprint(\"first five samples:\", samples[:5])\n\n# Compute basic statistics\nprint(\"mean =\", samples.mean())\nprint(\"std =\", samples.std())\n\nprint(\"25th percentile =\", np.percentile(samples, 25))\n\n# Histogram (counts per bin)\nhist, bins = np.histogram(samples, bins=5)\nprint(\"\\nhistogram:\")\nfor b_left, b_right, count in zip(bins[:-1], bins[1:], hist):\n    print(f\"{b_left: .2f} to {b_right: .2f}: {count}\")\n\n# Visualize the distribution\nplt.hist(samples, bins=30, density=True, alpha=0.7)\nplt.title(\"Histogram of random samples\")\nplt.xlabel(\"value\")\nplt.ylabel(\"density\")\nplt.show()\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Polynomial fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport matplotlib.pyplot as plt\n# Create noisy quadratic data\nrng = np.random.default_rng(0)\nx = np.linspace(-3, 3, 20)\ny = 0.5 * x**2 - x + 2 + rng.normal(scale=1.0, size=x.shape)\n\n# Fit a second degree polynomial\ncoeffs = np.polyfit(x, y, deg=2)\nprint(\"coefficients:\", coeffs)\n\n# Evaluate the fitted polynomial\np = np.poly1d(coeffs)\ny_fit = p(x)\n\n# Show first few fitted values\nprint(\"\\nfirst 5 fitted values:\", y_fit[:5])\n\n# Plot the data and fitted curve\nplt.scatter(x, y, label=\"data\")\nplt.plot(x, y_fit, color=\"red\", label=\"fit\")\nplt.title(\"Polynomial fit\")\nplt.legend()\nplt.show()\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\narr = np.arange(9).reshape(3, 3)\nprint(\"Original array:\\n\", arr)\n\nnp.save('array.npy', arr)\nprint('Array saved to array.npy')\n\nloaded = np.load('array.npy')\nprint('Loaded array:\\n', loaded)\n\n# Save multiple arrays in a compressed npz\nnp.savez_compressed('arrays.npz', first=arr, second=arr * 2)\ndata = np.load('arrays.npz')\nprint('\\nArrays in npz:', list(data.keys()))\n\nnp.savetxt('array.txt', arr, fmt='%d')\nprint('Also saved to array.txt')\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vectorization speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport time\nn = 1000000\ndata = np.arange(n)\n\n# Sum using Python loop\nstart = time.time()\ntotal = 0\nfor value in data:\n    total += value\nloop_time = time.time() - start\n\n# Sum using vectorized operation\nstart = time.time()\nvector_total = np.sum(data)\nvector_time = time.time() - start\n\nprint(\"loop sum =\", total, \"took\", loop_time, \"seconds\")\nprint(\"vectorized sum =\", vector_total, \"took\", vector_time, \"seconds\")\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. pandas basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n# Create a DataFrame from a Python dictionary\ndata = {\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n    \"age\": [25, 30, 35, 40],\n    \"score\": [85.5, 92.0, 88.0, 95.5],\n}\ndf = pd.DataFrame(data)\nprint(\"DataFrame:\\n\", df, \"\\n\")\n\n# Basic selection and summary statistics\nprint(\"Names column:\\n\", df[\"name\"])\nprint(\"Average age:\", df[\"age\"].mean())\nprint(\"Describe scores:\\n\", df[\"score\"].describe())\n\n# Simple visualization of the scores\ndf.plot.bar(x=\"name\", y=\"score\", title=\"Participant scores\", legend=False)\nimport matplotlib.pyplot as plt\nplt.xlabel(\"name\")\nplt.ylabel(\"score\")\nplt.tight_layout()\nplt.show()\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n# Load the Iris dataset from scikit-learn and put it in a DataFrame\niris = datasets.load_iris()\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf[\"target\"] = iris.target\n\n# Display the first few rows\nprint(\"First five rows:\\n\", df.head(), \"\\n\")\n\n# Summary statistics\nprint(\"Summary statistics:\\n\", df.describe(), \"\\n\")\n\n# Scatter plot of two features\ndf.plot.scatter(x=\"sepal length (cm)\", y=\"petal length (cm)\", c=\"target\", cmap=\"viridis\")\nplt.title(\"Iris feature scatter plot\")\nplt.show()\n\n# Histogram of petal widths\ndf[\"petal width (cm)\"].hist(bins=20)\nplt.title(\"Petal width distribution\")\nplt.xlabel(\"width (cm)\")\nplt.ylabel(\"count\")\nplt.show()\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. CSV input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n# Create a simple DataFrame\ndata = {\n    \"city\": [\"San Diego\", \"Los Angeles\", \"San Francisco\"],\n    \"population\": [1.4, 3.9, 0.88],\n}\ndf = pd.DataFrame(data)\nprint(\"Original DataFrame:\\n\", df, \"\\n\")\n\n# Write the DataFrame to CSV\ncsv_path = \"cities.csv\"\ndf.to_csv(csv_path, index=False)\nprint(f\"Data written to {csv_path}\")\n\n# Read the file back in\nloaded = pd.read_csv(csv_path)\nprint(\"\\nLoaded from CSV:\\n\", loaded)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. CIFAR-10 image exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n# Download CIFAR-10 training data\ntransform = transforms.ToTensor()\ncifar = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n\nprint(\"Number of images:\", len(cifar))\n\nloader = DataLoader(cifar, batch_size=4, shuffle=True)\nimages, labels = next(iter(loader))\n\n# Plot a few sample images\nfig, axes = plt.subplots(1, 4, figsize=(8, 2))\nfor img, ax in zip(images, axes):\n    ax.imshow(img.permute(1, 2, 0))\n    ax.axis(\"off\")\nplt.suptitle(\"CIFAR-10 samples\")\nplt.show()\n\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
